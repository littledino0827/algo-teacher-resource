#The purpose of this sample code is to illustrate how LSTM can be used to predict the stock price movement. However, #the key is to find the right stock, time period and parameters for LSTM

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split
import math
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error


# Go on QuantConnect to get historical bar data 
#df is the historical data on quant connect

df['logclose'] =df['close'].apply(lambda x: math.log(x))
df['logclose'] = df['logclose']- df['logclose'].iloc[0]  ## normalize to make the first column zero
#df1['logclose'] = df1['logclose']- df1['logclose'].iloc[0]
df['logclose_shift(1)'] = df['logclose'].shift(1)

df['logreturn'] = df['logclose'].diff(1).dropna()

features = ['logclose','close','volume']  # Input features #, 'logreturn'
target = 'logreturn'  # Output target to predict

# Scale the features
feature_scaler = MinMaxScaler(feature_range=(0, 1))
scaled_features = feature_scaler.fit_transform(np.array(df[features]))

# Scale the target
target_scaler = MinMaxScaler(feature_range=(0, 1))
scaled_target = target_scaler.fit_transform(df[target].values.reshape(-1, 1))

# Create sequences of data for LSTM
def create_sequences(data, target, time_steps=10):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(target[i + time_steps])
    return np.array(X), np.array(y)

# Define time steps (window size)
time_steps = 10

# Prepare the sequences
X, y = create_sequences(scaled_features, scaled_target, time_steps)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)

# Build the LSTM model
model = Sequential()
model.add(LSTM(40, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(40, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

# Get training predictions for comparison
y_train_pred = model.predict(X_train)

# Inverse transform the predictions and actual values for training data
y_train_pred_rescaled = target_scaler.inverse_transform(y_train_pred)
y_train_rescaled = target_scaler.inverse_transform(y_train)

# Get test predictions for comparison
y_test_pred = model.predict(X_test)

# Inverse transform the predictions and actual values for test data
y_test_pred_rescaled = target_scaler.inverse_transform(y_test_pred)
y_test_rescaled = target_scaler.inverse_transform(y_test)

# Compute the MSE - Mean Square Error

mse_train = mean_squared_error(y_train_rescaled, y_train_pred_rescaled)
mse_test= mean_squared_error(y_test_rescaled, y_test_pred_rescaled)

print(f'MSE Train: {mse_train}')
print(f'MSE Test: {mse_test}')